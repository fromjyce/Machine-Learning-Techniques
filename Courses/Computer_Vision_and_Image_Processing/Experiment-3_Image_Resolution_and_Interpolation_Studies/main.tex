\documentclass{report}

\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{mdframed}
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{amsmath}
\usepackage{listings} % For code formatting

% Configuration for code listings
\lstset{
    basicstyle=\ttfamily\small,
    frame=single,
    numbers=left,
    numberstyle=\tiny,
    keywordstyle=\color{blue}\bfseries,
    commentstyle=\color{gray},
    stringstyle=\color{red},
    showstringspaces=false,
    breaklines=true,
    postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space},
    tabsize=2
}

\begin{document}

\begin{titlepage}
\centering
\vspace*{\fill}
\huge{\textbf{CS3008: IMAGE AND VIDEO PROCESSING}}\\
\vspace{1 cm}

\begin{mdframed}
\centering
\LARGE{\textbf{LABORATORY REPORTS}}
\end{mdframed}

\vspace{3 cm}

\begin{flushleft}
\large{\textbf{Name: Jayashre\\
Roll No.: 22011103020 \\
College: Shiv Nadar University, Chennai\\}}

\vspace*{\fill}

\end{flushleft}
\end{titlepage}

\chapter{Eye Detection Using OpenCV} % Enable numbering for chapter

\section{Abstract}
This report documents the implementation of an eye detection system using the OpenCV library. The system utilizes Haar cascade classifiers to identify faces and eyes in images and marks them with bounding boxes. The project aims to provide a foundational understanding of image processing techniques and their practical applications.

\section{Introduction}
Eye detection plays a vital role in computer vision applications such as gaze tracking, facial recognition, and user interaction systems. This project implements a detection system using pre-trained Haar cascade classifiers, which efficiently identify facial and ocular features in images.

\section{Methodology}
\subsection{Data Collection}
The input data consists of static images containing human faces. The images were uploaded manually in the Google Colab environment for processing.

\subsection{Tools and Libraries}
\begin{itemize}
    \item \textbf{OpenCV}: For image processing and detection.
    \item \textbf{Google Colab}: For executing Python code and visualizing results.
\end{itemize}

\subsection{Detection Algorithm}
The steps followed in the implementation are:
\begin{enumerate}
    \item Convert the input image to grayscale for easier processing.
    \item Use the Haar cascade classifier to detect faces in the image.
    \item For each detected face, apply the Haar cascade classifier for eyes within the facial region.
    \item Highlight the detected features (faces and eyes) using bounding boxes.
\end{enumerate}

\section{Implementation}
The implementation was carried out in Python using OpenCV. The following code snippet demonstrates the detection process:

\begin{lstlisting}[language=Python, caption=Eye Detection Code, label=code:eye-detection]
import cv2
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
image = cv2.imread('input_image.jpg')
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5)

for (x, y, w, h) in faces:
    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)
    roi_gray = gray_image[y:y+h, x:x+w]
    roi_color = image[y:y+h, x:x+w]
    eyes = eye_cascade.detectMultiScale(roi_gray)
    for (ex, ey, ew, eh) in eyes:
        cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)
cv2.imwrite('output_image.jpg', image)
cv2.imshow('Eye Detection', image)
cv2.waitKey(0)
cv2.destroyAllWindows()
\end{lstlisting}

\section{Results and Discussion}
The system was tested with several images under various conditions. The results are summarized below:
\begin{itemize}
    \item Faces were detected accurately in well-lit images.
    \item Eye detection was successful but occasionally struggled with images where faces were partially obscured.
\end{itemize}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.4\textwidth]{images/Exp-1-Results.png} % Adjusted image size
    \caption{Detected faces and eyes in the input image.}
    \label{fig:output}
\end{figure}

\section{Conclusion}
The project successfully implemented an eye detection system using Haar cascades in OpenCV. While the system is efficient for basic detection, future improvements can involve the use of deep learning-based models for enhanced accuracy and robustness.

\chapter{Image Processing and Effects} % Enable numbering for chapter

\section{Abstract}
This report documents the implementation of various image processing techniques, including applying filters, resizing, cropping, rotating, and face mask overlays. These tasks showcase the practical applications of computer vision and image manipulation using Python and OpenCV.

\section{Introduction}
Image processing is a cornerstone of computer vision, enabling tasks like object detection, image enhancement, and feature extraction. This project demonstrates the use of OpenCV to apply filters and transformations to images, and overlay masks on detected faces.

\section{Methodology}
\subsection{Data Collection}
The input data consists of static images uploaded manually in the Google Colab environment. 

\subsection{Tools and Libraries}
\begin{itemize}
    \item \textbf{OpenCV}: For image processing and transformations.
    \item \textbf{Google Colab}: For executing Python code and visualizing results.
    \item \textbf{NumPy}: For handling numerical operations.
\end{itemize}

\subsection{Image Processing Techniques}
The project implements the following techniques:
\begin{itemize}
    \item Grayscale, sepia, negative, and blur effects.
    \item Edge detection and cartoonification.
    \item Image resizing, cropping, and rotation.
    \item Face detection with mask overlays.
    \item Dominant color extraction.
\end{itemize}

\section{Implementation}
The implementation was carried out in Python using OpenCV. The following code snippet demonstrates the overall process:

\begin{lstlisting}[language=Python, caption=Image Processing Code, label=code:image-processing]
import cv2
import numpy as np
from google.colab.patches import cv2_imshow

image_path = "content/sample.png"
img = cv2.imread(image_path)

def apply_grayscale(image):
    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

def apply_sepia(image):
    kernel = np.array([[0.393, 0.769, 0.189],
                       [0.349, 0.686, 0.168],
                       [0.272, 0.534, 0.131]])
    return cv2.transform(image, kernel)

def apply_negative(image):
    return cv2.bitwise_not(image)

def apply_blur(image, ksize=(5, 5)):
    return cv2.GaussianBlur(image, ksize, 0)

def apply_edge_detection(image):
    return cv2.Canny(image, 100, 200)

def apply_cartoonify(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray = cv2.medianBlur(gray, 5)
    edges = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 9)
    color = cv2.bilateralFilter(image, 9, 300, 300)
    return cv2.bitwise_and(color, color, mask=edges)

def resize_image(image, width=500):
    aspect_ratio = width / float(image.shape[1])
    height = int(image.shape[0] * aspect_ratio)
    return cv2.resize(image, (width, height))

def crop_image(image):
    height, width = image.shape[:2]
    size = min(height, width)
    center_x, center_y = width // 2, height // 2
    cropped = image[center_y - size // 2:center_y + size // 2, center_x - size // 2:center_x + size // 2]
    return cropped

def rotate_image(image, angle=45):
    height, width = image.shape[:2]
    center = (width // 2, height // 2)
    matrix = cv2.getRotationMatrix2D(center, angle, 1)
    rotated = cv2.warpAffine(image, matrix, (width, height))
    return rotated


grayscale_img = apply_grayscale(img)
sepia_img = apply_sepia(img)
negative_img = apply_negative(img)
blur_img = apply_blur(img)
edges_img = apply_edge_detection(img)
cartoon_img = apply_cartoonify(img)
resized_img = resize_image(img)
cropped_img = crop_image(img)
rotated_img = rotate_image(img)

cv2_imshow(grayscale_img)
cv2_imshow(sepia_img)
cv2_imshow(negative_img)
cv2_imshow(blur_img)
cv2_imshow(edges_img)
cv2_imshow(cartoon_img)
cv2_imshow(resized_img)
cv2_imshow(cropped_img)
cv2_imshow(rotated_img)
\end{lstlisting}

\section{Results and Discussion}
The following observations were made during testing:
\begin{itemize}
    \item Filters like grayscale, sepia, and negative worked as expected.
    \item Cartoonification produced visually appealing results by emphasizing edges.
    \item Face detection accurately identified facial regions for mask overlays.
    \item Dominant color extraction provided a clear representation of the primary colors in images.
\end{itemize}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.4\textwidth]{images/Exp-2-Results.png} % Adjusted image size
    \caption{Examples of applied filters and transformations.}
    \label{fig:output}
\end{figure}

\section{Conclusion}
This project successfully demonstrated various image processing techniques using OpenCV. Future work could explore integrating deep learning models for more advanced image transformations and processing.

\chapter{Image Resolution and Interpolation Studies} % Enable numbering for chapter

\section{Abstract}
This report explores the fundamental concepts of image resolution and interpolation in image processing. The experiments involve converting RGB images to grayscale using a formula, analyzing intensity and spatial resolution changes, and studying image interpolation techniques. The study aims to provide insights into how image transformations affect visual quality and data representation.

\section{Introduction}
Image resolution and interpolation are critical aspects of image processing. Resolution defines the level of detail in an image, while interpolation determines how images are scaled to different dimensions. This project investigates these aspects through practical implementations and analyses their impact on image quality.

\section{Methodology}
\subsection{Tools and Libraries}
\begin{itemize}
    \item \textbf{OpenCV}: For image processing operations.
    \item \textbf{NumPy}: For numerical computations.
    \item \textbf{Google Colab}: For implementation and visualization.
\end{itemize}

\subsection{Experiments Conducted}
\begin{enumerate}
    \item \textbf{Convert RGB to Grayscale:} An RGB image is converted to grayscale using the formula:
    \[ Y = 0.299 \cdot R + 0.587 \cdot G + 0.114 \cdot B \]

    \item \textbf{Intensity Resolution:} An 8-bit grayscale image is converted into 7, 6, 5, 4, 3, and 2-bit images by reducing the bit depth and analyzing the resulting quality loss.

    \item \textbf{Spatial Resolution:} A 512x512 image is resized to 256x256, 128x128, 64x64, and 32x32 dimensions to observe the effect of reduced spatial resolution.

    \item \textbf{Image Interpolation:} A 128x128 image is resized to 256x256 and 512x512 dimensions using bilinear and bicubic interpolation techniques.
\end{enumerate}

\section{Implementation}
The implementation was carried out using Python and OpenCV. The following snippets showcase the key operations:

\begin{lstlisting}[language=Python, caption=Convert RGB to Grayscale, label=code:grayscale]
import cv2
import numpy as np
import matplotlib.pyplot as plt

image = cv2.imread('/content/image.jpg')

image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

R = image_rgb[:, :, 0]
G = image_rgb[:, :, 1]
B = image_rgb[:, :, 2]

gray_image = 0.299 * R + 0.587 * G + 0.114 * B
gray_image = gray_image.astype(np.uint8)

plt.imshow(gray_image, cmap='gray')
plt.title("Grayscale Image (Formula)")
plt.axis('off')
plt.show()
\end{lstlisting}

\begin{lstlisting}[language=Python, caption=Bit Depth Reduction, label=code:intensity-resolution]
import numpy as np
import cv2
import matplotlib.pyplot as plt

image = cv2.imread('/content/image.jpg', cv2.IMREAD_GRAYSCALE)

def reduce_intensity_resolution(image, bits):
    max_intensity = 2**bits - 1
    return np.uint8((image / 256) * max_intensity)

bit_depths = [7, 6, 5, 4, 3, 2]
for bits in bit_depths:
    reduced_image = reduce_intensity_resolution(image, bits)
    plt.imshow(reduced_image, cmap='gray')
    plt.title(f"{bits}-bit Image")
    plt.axis('off')
    plt.show()
\end{lstlisting}

\begin{lstlisting}[language=Python, caption=Spatial Resolution Adjustment, label=code:spatial-resolution]
import cv2
import matplotlib.pyplot as plt

image = cv2.imread('/content/penguin.jpg', cv2.IMREAD_GRAYSCALE)

def resize_image(image, size):
    return cv2.resize(image, (size, size), interpolation=cv2.INTER_LINEAR)

sizes = [256, 128, 64, 32]
for size in sizes:
    resized_image = resize_image(image, size)
    plt.imshow(resized_image, cmap='gray')
    plt.title(f"{size}x{size} Image")
    plt.axis('off')
    plt.show()
    cv2.imwrite(f'{size}x{size}_image.jpg', resized_image)
\end{lstlisting}

\begin{lstlisting}[language=Python, caption=Image Interpolation, label=code:interpolation]
import cv2
import matplotlib.pyplot as plt

image = cv2.imread('/content/sunset.jpg', cv2.IMREAD_GRAYSCALE)

def upscale_image(image, new_size, interpolation_method):
    return cv2.resize(image, (new_size, new_size), interpolation=interpolation_method)
interpolation_methods = {
    'Nearest Neighbor': cv2.INTER_NEAREST,
    'Bilinear': cv2.INTER_LINEAR,
    'Bicubic': cv2.INTER_CUBIC
}

sizes = [256, 512]
for size in sizes:
    for method_name, method in interpolation_methods.items():
        upscaled_image = upscale_image(image, size, method)
        plt.imshow(upscaled_image, cmap='gray')
        plt.title(f"{size}x{size} Image with {method_name} Interpolation")
        plt.axis('off')
        plt.show()
        cv2.imwrite(f'{size}x{size}_{method_name}_interpolation.jpg', upscaled_image)
\end{lstlisting}

\section{Results and Discussion}
\subsection{RGB to Grayscale}
The grayscale conversion effectively reduced the color data of the image while preserving its luminance, demonstrating the precision of the formula.

\subsection{Intensity Resolution}
The reduction in bit depth showed a gradual loss in image quality. Higher bit depths retained more details, while lower depths introduced noticeable quantization artifacts.

\subsection{Spatial Resolution}
Decreasing the spatial resolution led to a loss of detail and sharpness. However, the images remained recognizable at lower resolutions, demonstrating the trade-off between quality and storage requirements.

\subsection{Image Interpolation}
Bilinear and bicubic interpolation effectively upscaled the images. Bicubic interpolation provided smoother results but required higher computational resources compared to bilinear interpolation.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.4\textwidth]{images/Exp-3-Results-1.png} % Placeholder for results image
    \caption{Conversion RGB to Grayscale}
    \label{fig:exp-3-results}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.4\textwidth]{images/Exp-3-Results-2.png} % Placeholder for results image
    \caption{Intensity Resolution.}
    \label{fig:exp-3-results}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.4\textwidth]{images/Exp-3-Results-3.png} % Placeholder for results image
    \caption{Spatial Resolution.}
    \label{fig:exp-3-results}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.4\textwidth]{images/Exp-3-Results-4.png} % Placeholder for results image
    \caption{Image Interpolation.}
    \label{fig:exp-3-results}
\end{figure}

\section{Conclusion}
The experiments provided insights into how resolution and interpolation affect image quality. Future work can involve exploring advanced interpolation techniques, such as deep learning-based methods, for higher accuracy and efficiency.

\end{document}

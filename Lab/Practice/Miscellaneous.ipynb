{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Cross Validation, Ensemble Methods, Regularization, Feature Selection"
      ],
      "metadata": {
        "id": "8tBKuo67RD_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Define the model\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Perform cross-validation\n",
        "scores = cross_val_score(model, X_train, y_train, cv=5)  # cv specifies the number of folds\n",
        "\n",
        "# Print the cross-validation scores\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Mean cross-validation score:\", np.mean(scores))\n"
      ],
      "metadata": {
        "id": "CkYzKCHHRNy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define base classifiers\n",
        "base_classifier = DecisionTreeClassifier()\n",
        "\n",
        "# Bagging\n",
        "bagging_model = BaggingClassifier(base_estimator=base_classifier, n_estimators=10)\n",
        "bagging_model.fit(X_train, y_train)\n",
        "\n",
        "# Boosting (AdaBoost)\n",
        "adaboost_model = AdaBoostClassifier(base_estimator=base_classifier, n_estimators=50, learning_rate=1.0)\n",
        "adaboost_model.fit(X_train, y_train)\n",
        "\n",
        "# Stacking\n",
        "stacking_model = StackingClassifier(estimators=[('bagging', bagging_model), ('adaboost', adaboost_model)],\n",
        "                                    final_estimator=LogisticRegression())\n",
        "stacking_model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "oXqtTYYXRQE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "\n",
        "# Ridge Regression\n",
        "ridge_model = Ridge(alpha=0.5)  # Alpha is the regularization strength\n",
        "ridge_model.fit(X_train, y_train)\n",
        "\n",
        "# Lasso Regression\n",
        "lasso_model = Lasso(alpha=0.1)  # Alpha is the regularization strength\n",
        "lasso_model.fit(X_train, y_train)\n",
        "\n",
        "# ElasticNet Regression\n",
        "elasticnet_model = ElasticNet(alpha=0.1, l1_ratio=0.5)  # Alpha is the regularization strength, l1_ratio controls the balance between L1 and L2 penalties\n",
        "elasticnet_model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "tHQFgmrJRTBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2, f_classif, RFE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# SelectKBest with chi-square test for classification\n",
        "selector = SelectKBest(score_func=chi2, k=5)  # Select top 5 features\n",
        "X_selected = selector.fit_transform(X_train, y_train)\n",
        "\n",
        "# Print selected features\n",
        "selected_features = np.array(X.columns)[selector.get_support()]\n",
        "print(\"Selected features using SelectKBest:\", selected_features)\n",
        "\n",
        "# RFE with RandomForestClassifier for feature selection\n",
        "estimator = RandomForestClassifier(n_estimators=10)\n",
        "selector_rfe = RFE(estimator, n_features_to_select=5, step=1)  # Select top 5 features\n",
        "selector_rfe.fit(X_train, y_train)\n",
        "\n",
        "# Print selected features\n",
        "selected_features_rfe = np.array(X.columns)[selector_rfe.support_]\n",
        "print(\"Selected features using RFE:\", selected_features_rfe)\n",
        "\n",
        "# Example usage with Logistic Regression after feature selection\n",
        "logistic_regression = LogisticRegression()\n",
        "logistic_regression.fit(X_selected, y_train)\n"
      ],
      "metadata": {
        "id": "YCCMsAqORekT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Importance"
      ],
      "metadata": {
        "id": "6EvV8DxcRrYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Train a Random Forest classifier\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = clf.feature_importances_\n",
        "\n",
        "# Print feature importances\n",
        "for i, importance in enumerate(feature_importances):\n",
        "    print(\"Feature {}: {}\".format(i+1, importance))\n"
      ],
      "metadata": {
        "id": "QoZh21BLRt7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train a logistic regression model\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Get feature coefficients\n",
        "feature_coefficients = clf.coef_[0]\n",
        "\n",
        "# Print feature coefficients\n",
        "for i, coefficient in enumerate(feature_coefficients):\n",
        "    print(\"Feature {}: {}\".format(i+1, coefficient))\n"
      ],
      "metadata": {
        "id": "tPU_huq_Rw00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Train a Gradient Boosting classifier\n",
        "clf = GradientBoostingClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = clf.feature_importances_\n",
        "\n",
        "# Print feature importances\n",
        "for i, importance in enumerate(feature_importances):\n",
        "    print(\"Feature {}: {}\".format(i+1, importance))\n"
      ],
      "metadata": {
        "id": "TNsslVt6RypG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Permutation importance\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Train an SVM classifier\n",
        "clf = SVC()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Calculate permutation importance\n",
        "perm_importance = permutation_importance(clf, X_test, y_test)\n",
        "\n",
        "# Print permutation importance\n",
        "for i, importance in enumerate(perm_importance.importances_mean):\n",
        "    print(\"Feature {}: {}\".format(i+1, importance))\n"
      ],
      "metadata": {
        "id": "n55WK0ueRzoq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
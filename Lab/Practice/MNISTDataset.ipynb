{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR_X5EfICYgZ",
        "outputId": "28d3e50c-37d0-47b4-cb9d-cb0676262104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X, y = mnist[\"data\"], mnist[\"target\"]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling (normalize pixel values to range [0, 1])\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# KNN classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors (k)\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_train = knn.predict(X_train_scaled)\n",
        "y_pred_test = knn.predict(X_test_scaled)\n",
        "\n",
        "# Calculate accuracy\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"Train Accuracy:\", train_accuracy)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X, y = mnist[\"data\"], mnist[\"target\"]\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling (normalize pixel values to range [0, 1])\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Hierarchical clustering\n",
        "agg_clustering = AgglomerativeClustering(n_clusters=10)  # You can adjust the number of clusters\n",
        "agg_clustering.fit(X_train_scaled)\n",
        "\n",
        "# Assign cluster labels\n",
        "train_cluster_labels = agg_clustering.labels_\n",
        "\n",
        "# Predict cluster labels for test set\n",
        "test_cluster_labels = agg_clustering.fit_predict(X_test_scaled)\n",
        "\n",
        "# Map cluster labels to digit labels based on majority voting\n",
        "cluster_to_digit = {}\n",
        "for cluster in np.unique(train_cluster_labels):\n",
        "    digit_labels = y_train[train_cluster_labels == cluster]\n",
        "    cluster_to_digit[cluster] = np.argmax(np.bincount(digit_labels.astype(int)))\n",
        "\n",
        "# Predict digit labels for test set\n",
        "y_pred_test = [cluster_to_digit[cluster] for cluster in test_cluster_labels]\n",
        "\n",
        "# Calculate accuracy\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"Test Accuracy (Hierarchical Clustering):\", test_accuracy)\n"
      ],
      "metadata": {
        "id": "elVdCCasCcHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC()\n",
        "\n",
        "param_grid = {'C': [0.1, 1, 10],\n",
        "              'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "              'gamma': ['scale', 'auto']}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy:\", grid_search.best_score_)\n"
      ],
      "metadata": {
        "id": "ZZ9UPb02CyeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "param_grid = {'n_estimators': [50, 100, 200],\n",
        "              'max_depth': [5, 10, None]}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy:\", grid_search.best_score_)\n"
      ],
      "metadata": {
        "id": "YT1c3ZeoEApN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "param_grid = {'C': [0.1, 1, 10]}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy:\", grid_search.best_score_)\n"
      ],
      "metadata": {
        "id": "IjCmf-fxECvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gbm = GradientBoostingClassifier()\n",
        "\n",
        "param_grid = {'learning_rate': [0.01, 0.1, 1],\n",
        "              'n_estimators': [50, 100, 200],\n",
        "              'max_depth': [3, 5, 7]}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=gbm, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy:\", grid_search.best_score_)\n"
      ],
      "metadata": {
        "id": "O71qHvYaEJxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier()\n",
        "\n",
        "param_grid = {'hidden_layer_sizes': [(50,), (100,), (200,)],\n",
        "              'activation': ['relu', 'tanh'],\n",
        "              'alpha': [0.0001, 0.001, 0.01]}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy:\", grid_search.best_score_)\n"
      ],
      "metadata": {
        "id": "rB94sheVELh9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dXW-K1kHJAa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"online_food_dataset.csv\")\n",
        "\n",
        "# Perform data preprocessing\n",
        "# Assume 'X' contains features and 'y' contains the target variable\n",
        "X = data.drop(columns=['target_column'])\n",
        "y = data['target_column']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Polynomial Regression\n",
        "poly_reg = Pipeline([\n",
        "    ('poly', PolynomialFeatures(degree=2)),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('regressor', SVR())  # You can replace SVR with any other regression model\n",
        "])\n",
        "\n",
        "# Support Vector Machine\n",
        "svm_reg = SVR()\n",
        "\n",
        "# Gradient Boosting Machine\n",
        "gbm_reg = GradientBoostingRegressor()\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV\n",
        "params = {\n",
        "    'regressor__C': [0.1, 1, 10],  # SVM regularization parameter\n",
        "    'regressor__kernel': ['linear', 'rbf'],  # SVM kernel\n",
        "    'regressor__gamma': ['scale', 'auto'],  # SVM kernel coefficient\n",
        "    'n_estimators': [50, 100, 200],  # Number of boosting stages to perform\n",
        "    'learning_rate': [0.05, 0.1, 0.2],  # Boosting learning rate\n",
        "    'max_depth': [3, 4, 5]  # Maximum depth of the individual trees\n",
        "}\n",
        "\n",
        "# Grid search for each model\n",
        "poly_reg_grid = GridSearchCV(poly_reg, params, cv=5, scoring='neg_mean_squared_error')\n",
        "svm_reg_grid = GridSearchCV(svm_reg, params, cv=5, scoring='neg_mean_squared_error')\n",
        "gbm_reg_grid = GridSearchCV(gbm_reg, params, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit the models\n",
        "poly_reg_grid.fit(X_train, y_train)\n",
        "svm_reg_grid.fit(X_train, y_train)\n",
        "gbm_reg_grid.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate models\n",
        "poly_reg_rmse = np.sqrt(mean_squared_error(y_test, poly_reg_grid.predict(X_test)))\n",
        "svm_reg_rmse = np.sqrt(mean_squared_error(y_test, svm_reg_grid.predict(X_test)))\n",
        "gbm_reg_rmse = np.sqrt(mean_squared_error(y_test, gbm_reg_grid.predict(X_test)))\n",
        "\n",
        "print(\"Polynomial Regression RMSE:\", poly_reg_rmse)\n",
        "print(\"SVM RMSE:\", svm_reg_rmse)\n",
        "print(\"GBM RMSE:\", gbm_reg_rmse)\n",
        "\n",
        "# Best hyperparameters for each model\n",
        "print(\"Best Polynomial Regression parameters:\", poly_reg_grid.best_params_)\n",
        "print(\"Best SVM parameters:\", svm_reg_grid.best_params_)\n",
        "print(\"Best GBM parameters:\", gbm_reg_grid.best_params_)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"online_food_dataset.csv\")\n",
        "\n",
        "# Perform data preprocessing\n",
        "# Assume 'X' contains features and 'y' contains the target variable\n",
        "X = data.drop(columns=['target_column'])\n",
        "y = data['target_column']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Random Forest\n",
        "rf_reg = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# XGBoost\n",
        "xgb_reg = XGBRegressor(random_state=42)\n",
        "\n",
        "# K-Nearest Neighbors\n",
        "knn_reg = KNeighborsRegressor()\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV\n",
        "params_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "params_xgb = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.05, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "params_knn = {\n",
        "    'n_neighbors': [3, 5, 7],\n",
        "    'weights': ['uniform', 'distance']\n",
        "}\n",
        "\n",
        "# Grid search for each model\n",
        "rf_reg_grid = GridSearchCV(rf_reg, params_rf, cv=5, scoring='neg_mean_squared_error')\n",
        "xgb_reg_grid = GridSearchCV(xgb_reg, params_xgb, cv=5, scoring='neg_mean_squared_error')\n",
        "knn_reg_grid = GridSearchCV(knn_reg, params_knn, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit the models\n",
        "rf_reg_grid.fit(X_train_scaled, y_train)\n",
        "xgb_reg_grid.fit(X_train_scaled, y_train)\n",
        "knn_reg_grid.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate models\n",
        "rf_reg_rmse = np.sqrt(mean_squared_error(y_test, rf_reg_grid.predict(X_test_scaled)))\n",
        "xgb_reg_rmse = np.sqrt(mean_squared_error(y_test, xgb_reg_grid.predict(X_test_scaled)))\n",
        "knn_reg_rmse = np.sqrt(mean_squared_error(y_test, knn_reg_grid.predict(X_test_scaled)))\n",
        "\n",
        "print(\"Random Forest RMSE:\", rf_reg_rmse)\n",
        "print(\"XGBoost RMSE:\", xgb_reg_rmse)\n",
        "print(\"KNN RMSE:\", knn_reg_rmse)\n",
        "\n",
        "# Best hyperparameters for each model\n",
        "print(\"Best Random Forest parameters:\", rf_reg_grid.best_params_)\n",
        "print(\"Best XGBoost parameters:\", xgb_reg_grid.best_params_)\n",
        "print(\"Best KNN parameters:\", knn_reg_grid.best_params_)\n"
      ],
      "metadata": {
        "id": "SjInJ-sQHPdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Decision Tree\n",
        "dt_reg = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Random Forest\n",
        "rf_reg = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Fit the models\n",
        "dt_reg.fit(X_train_scaled, y_train)\n",
        "rf_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate models\n",
        "dt_reg_rmse = np.sqrt(mean_squared_error(y_test, dt_reg.predict(X_test_scaled)))\n",
        "rf_reg_rmse = np.sqrt(mean_squared_error(y_test, rf_reg.predict(X_test_scaled)))\n",
        "\n",
        "print(\"Decision Tree RMSE:\", dt_reg_rmse)\n",
        "print(\"Random Forest RMSE:\", rf_reg_rmse)\n"
      ],
      "metadata": {
        "id": "Dh1G419uH9Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# SVR with polynomial kernel\n",
        "svr_poly = SVR(kernel='poly')\n",
        "\n",
        "# SVR with sigmoid kernel\n",
        "svr_sigmoid = SVR(kernel='sigmoid')\n",
        "\n",
        "# Fit the models\n",
        "svr_poly.fit(X_train_scaled, y_train)\n",
        "svr_sigmoid.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate models\n",
        "svr_poly_rmse = np.sqrt(mean_squared_error(y_test, svr_poly.predict(X_test_scaled)))\n",
        "svr_sigmoid_rmse = np.sqrt(mean_squared_error(y_test, svr_sigmoid.predict(X_test_scaled)))\n",
        "\n",
        "print(\"SVR with Polynomial Kernel RMSE:\", svr_poly_rmse)\n",
        "print(\"SVR with Sigmoid Kernel RMSE:\", svr_sigmoid_rmse)\n"
      ],
      "metadata": {
        "id": "DhmzQZa5H_gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Ridge Regression\n",
        "ridge_reg = Ridge(alpha=1.0)  # You can adjust the regularization strength (alpha) as needed\n",
        "\n",
        "# Fit the model\n",
        "ridge_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "ridge_reg_rmse = np.sqrt(mean_squared_error(y_test, ridge_reg.predict(X_test_scaled)))\n",
        "\n",
        "print(\"Ridge Regression RMSE:\", ridge_reg_rmse)"
      ],
      "metadata": {
        "id": "b5UMF7jUICKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Base estimators for stacking\n",
        "estimators = [\n",
        "    ('random_forest', RandomForestRegressor(random_state=42)),\n",
        "    ('svr', SVR(kernel='rbf')),\n",
        "    ('ridge', Ridge(alpha=1.0))\n",
        "]\n",
        "\n",
        "# Stacking Regressor\n",
        "stacking_reg = StackingRegressor(\n",
        "    estimators=estimators,\n",
        "    final_estimator=LinearRegression()\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "stacking_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "stacking_reg_rmse = np.sqrt(mean_squared_error(y_test, stacking_reg.predict(X_test_scaled)))\n",
        "\n",
        "print(\"Stacking Regressor RMSE:\", stacking_reg_rmse)"
      ],
      "metadata": {
        "id": "TtbTBm-DIElq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}